D:\Anaconda\envs\dejahu\python.exe C:\Users\xiao\Desktop\dejahu\vegetables_tf2.3-master\train_cnn.py
Found 13211 files belonging to 104 classes.
2024-07-13 10:56:46.444024: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-07-13 10:56:46.450033: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1eae548e390 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-07-13 10:56:46.450223: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Found 3225 files belonging to 104 classes.
['alpine sea holly', 'anthurium', 'artichoke', 'azalea', 'balloon flower', 'barberton daisy', 'bee balm', 'bird of paradise', 'bishop of llandaff', 'black-eyed susan', 'blackberry lily', 'blanket flower', 'bolero deep blue', 'bougainvillea', 'bromelia', 'buttercup', 'californian poppy', 'camellia', 'canna lily', 'canterbury bells', 'cape flower', 'carnation', 'cautleya spicata', 'clematis', "colt's foot", 'columbine', 'common dandelion', 'common tulip', 'corn poppy', 'cosmos', 'cyclamen', 'daffodil', 'daisy', 'desert-rose', 'fire lily', 'foxglove', 'frangipani', 'fritillary', 'garden phlox', 'gaura', 'gazania', 'geranium', 'giant white arum lily', 'globe thistle', 'globe-flower', 'grape hyacinth', 'great masterwort', 'hard-leaved pocket orchid', 'hibiscus', 'hippeastrum', 'iris', 'japanese anemone', 'king protea', 'lenten rose', 'lilac hibiscus', 'lotus', 'love in the mist', 'magnolia', 'mallow', 'marigold', 'mexican petunia', 'monkshood', 'moon orchid', 'morning glory', 'orange dahlia', 'osteospermum', 'passion flower', 'peruvian lily', 'petunia', 'pincushion flower', 'pink primrose', 'pink quill', 'pink-yellow dahlia', 'poinsettia', 'primula', 'prince of wales feathers', 'purple coneflower', 'red ginger', 'rose', 'ruby-lipped cattleya', 'siam tulip', 'silverbush', 'snapdragon', 'spear thistle', 'spring crocus', 'stemless gentian', 'sunflower', 'sweet pea', 'sweet william', 'sword lily', 'thorn apple', 'tiger lily', 'toad lily', 'tree mallow', 'tree poppy', 'trumpet creeper', 'wallflower', 'water lily', 'watercress', 'wild geranium', 'wild pansy', 'wild rose', 'windflower', 'yellow iris']
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
rescaling (Rescaling)        (None, 224, 224, 3)       0
_________________________________________________________________
conv2d (Conv2D)              (None, 222, 222, 32)      896
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 109, 109, 64)      18496
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0
_________________________________________________________________
flatten (Flatten)            (None, 186624)            0
_________________________________________________________________
dense (Dense)                (None, 128)               23888000
_________________________________________________________________
dense_1 (Dense)              (None, 104)               13416
=================================================================
Total params: 23,920,808
Trainable params: 23,920,808
Non-trainable params: 0
_________________________________________________________________
Epoch 1/30
826/826 [==============================] - 299s 363ms/step - loss: 3.8314 - accuracy: 0.1201 - val_loss: 3.4363 - val_accuracy: 0.1625
Epoch 2/30
826/826 [==============================] - 216s 262ms/step - loss: 3.2329 - accuracy: 0.1977 - val_loss: 3.1819 - val_accuracy: 0.2000
Epoch 3/30
826/826 [==============================] - 217s 263ms/step - loss: 2.9142 - accuracy: 0.2520 - val_loss: 2.9923 - val_accuracy: 0.2527
Epoch 4/30
826/826 [==============================] - 217s 263ms/step - loss: 2.6482 - accuracy: 0.3064 - val_loss: 3.1671 - val_accuracy: 0.2341
Epoch 5/30
826/826 [==============================] - 214s 259ms/step - loss: 2.3503 - accuracy: 0.3783 - val_loss: 2.9903 - val_accuracy: 0.2840
Epoch 6/30
826/826 [==============================] - 215s 260ms/step - loss: 1.9962 - accuracy: 0.4601 - val_loss: 3.0528 - val_accuracy: 0.2716
Epoch 7/30
826/826 [==============================] - 214s 260ms/step - loss: 1.5206 - accuracy: 0.5794 - val_loss: 3.6564 - val_accuracy: 0.2357
Epoch 8/30
826/826 [==============================] - 217s 263ms/step - loss: 0.9602 - accuracy: 0.7407 - val_loss: 3.5233 - val_accuracy: 0.2896
Epoch 9/30
826/826 [==============================] - 215s 260ms/step - loss: 0.4917 - accuracy: 0.8662 - val_loss: 4.0034 - val_accuracy: 0.2871
Epoch 10/30
826/826 [==============================] - 216s 261ms/step - loss: 0.2479 - accuracy: 0.9332 - val_loss: 4.3530 - val_accuracy: 0.2930
Epoch 11/30
826/826 [==============================] - 214s 259ms/step - loss: 0.1077 - accuracy: 0.9722 - val_loss: 4.7083 - val_accuracy: 0.2890
Epoch 12/30
826/826 [==============================] - 219s 265ms/step - loss: 0.0576 - accuracy: 0.9871 - val_loss: 4.8667 - val_accuracy: 0.3039
Epoch 13/30
826/826 [==============================] - 218s 264ms/step - loss: 0.0403 - accuracy: 0.9908 - val_loss: 5.1527 - val_accuracy: 0.3042
Epoch 14/30
826/826 [==============================] - 230s 278ms/step - loss: 0.0185 - accuracy: 0.9968 - val_loss: 5.4014 - val_accuracy: 0.3088
Epoch 15/30
826/826 [==============================] - 214s 260ms/step - loss: 0.0171 - accuracy: 0.9971 - val_loss: 5.3088 - val_accuracy: 0.3116
Epoch 16/30
826/826 [==============================] - 216s 261ms/step - loss: 0.0133 - accuracy: 0.9973 - val_loss: 5.4044 - val_accuracy: 0.3098
Epoch 17/30
826/826 [==============================] - 224s 271ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.7345 - val_accuracy: 0.3163
Epoch 18/30
826/826 [==============================] - 221s 268ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.8820 - val_accuracy: 0.3160
Epoch 19/30
826/826 [==============================] - 215s 260ms/step - loss: 9.1175e-04 - accuracy: 1.0000 - val_loss: 5.9818 - val_accuracy: 0.3138
Epoch 20/30
826/826 [==============================] - 214s 260ms/step - loss: 7.4961e-04 - accuracy: 1.0000 - val_loss: 6.0656 - val_accuracy: 0.3153
Epoch 21/30
826/826 [==============================] - 228s 275ms/step - loss: 6.4196e-04 - accuracy: 1.0000 - val_loss: 6.1334 - val_accuracy: 0.3157
Epoch 22/30
826/826 [==============================] - 223s 270ms/step - loss: 5.6355e-04 - accuracy: 1.0000 - val_loss: 6.1942 - val_accuracy: 0.3169
Epoch 23/30
826/826 [==============================] - 216s 262ms/step - loss: 5.0397e-04 - accuracy: 1.0000 - val_loss: 6.2452 - val_accuracy: 0.3172
Epoch 24/30
826/826 [==============================] - 214s 259ms/step - loss: 4.5710e-04 - accuracy: 1.0000 - val_loss: 6.2925 - val_accuracy: 0.3178
Epoch 25/30
826/826 [==============================] - 214s 259ms/step - loss: 4.1880e-04 - accuracy: 1.0000 - val_loss: 6.3344 - val_accuracy: 0.3178
Epoch 26/30
826/826 [==============================] - 215s 261ms/step - loss: 3.8598e-04 - accuracy: 1.0000 - val_loss: 6.3746 - val_accuracy: 0.3188
Epoch 27/30
826/826 [==============================] - 214s 260ms/step - loss: 3.5875e-04 - accuracy: 1.0000 - val_loss: 6.4115 - val_accuracy: 0.3191
Epoch 28/30
826/826 [==============================] - 214s 259ms/step - loss: 3.3498e-04 - accuracy: 1.0000 - val_loss: 6.4449 - val_accuracy: 0.3191
Epoch 29/30
826/826 [==============================] - 219s 265ms/step - loss: 3.1437e-04 - accuracy: 1.0000 - val_loss: 6.4766 - val_accuracy: 0.3194
Epoch 30/30
826/826 [==============================] - 226s 274ms/step - loss: 2.9619e-04 - accuracy: 1.0000 - val_loss: 6.5063 - val_accuracy: 0.3188
该循环程序运行时间： 6626.250611305237 s

进程已结束，退出代码为 0
